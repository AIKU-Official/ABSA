wandb_version: 1

adafactor_beta1:
  desc: null
  value: null
adafactor_clip_threshold:
  desc: null
  value: 1.0
adafactor_decay_rate:
  desc: null
  value: -0.8
adafactor_eps:
  desc: null
  value:
  - 1.0e-30
  - 0.001
adafactor_relative_step:
  desc: null
  value: true
adafactor_scale_parameter:
  desc: null
  value: true
adafactor_warmup_init:
  desc: null
  value: true
adam_betas:
  desc: null
  value:
  - 0.9
  - 0.999
adam_epsilon:
  desc: null
  value: 1.0e-08
best_model_dir:
  desc: null
  value: outputs/best_model
cache_dir:
  desc: null
  value: cache_dir/
config:
  desc: null
  value: {}
cosine_schedule_num_cycles:
  desc: null
  value: 0.5
custom_layer_parameters:
  desc: null
  value: []
custom_parameter_groups:
  desc: null
  value: []
dataloader_num_workers:
  desc: null
  value: 0
do_lower_case:
  desc: null
  value: false
dynamic_quantize:
  desc: null
  value: false
early_stopping_consider_epochs:
  desc: null
  value: false
early_stopping_delta:
  desc: null
  value: 0
early_stopping_metric:
  desc: null
  value: eval_loss
early_stopping_metric_minimize:
  desc: null
  value: true
early_stopping_patience:
  desc: null
  value: 3
encoding:
  desc: null
  value: null
eval_batch_size:
  desc: null
  value: 8
evaluate_during_training:
  desc: null
  value: false
evaluate_during_training_silent:
  desc: null
  value: true
evaluate_during_training_steps:
  desc: null
  value: 2000
evaluate_during_training_verbose:
  desc: null
  value: false
evaluate_each_epoch:
  desc: null
  value: true
fp16:
  desc: null
  value: true
gradient_accumulation_steps:
  desc: null
  value: 1
learning_rate:
  desc: null
  value: 4.0e-05
local_rank:
  desc: null
  value: -1
logging_steps:
  desc: null
  value: 50
loss_type:
  desc: null
  value: null
loss_args:
  desc: null
  value: {}
manual_seed:
  desc: null
  value: 42
max_grad_norm:
  desc: null
  value: 1.0
max_seq_length:
  desc: null
  value: 256
model_name:
  desc: null
  value: gogamza/kobart-base-v2
model_type:
  desc: null
  value: bart
multiprocessing_chunksize:
  desc: null
  value: -1
n_gpu:
  desc: null
  value: 1
no_cache:
  desc: null
  value: false
no_save:
  desc: null
  value: false
not_saved_args:
  desc: null
  value: []
num_train_epochs:
  desc: null
  value: 15
optimizer:
  desc: null
  value: AdamW
output_dir:
  desc: null
  value: outputs/
overwrite_output_dir:
  desc: null
  value: true
polynomial_decay_schedule_lr_end:
  desc: null
  value: 1.0e-07
polynomial_decay_schedule_power:
  desc: null
  value: 1.0
process_count:
  desc: null
  value: 10
quantized_model:
  desc: null
  value: false
reprocess_input_data:
  desc: null
  value: true
save_best_model:
  desc: null
  value: true
save_eval_checkpoints:
  desc: null
  value: false
save_model_every_epoch:
  desc: null
  value: true
save_optimizer_and_scheduler:
  desc: null
  value: true
save_steps:
  desc: null
  value: 99999999999999
scheduler:
  desc: null
  value: linear_schedule_with_warmup
silent:
  desc: null
  value: false
skip_special_tokens:
  desc: null
  value: true
tensorboard_dir:
  desc: null
  value: null
thread_count:
  desc: null
  value: null
tokenizer_name:
  desc: null
  value: null
tokenizer_type:
  desc: null
  value: null
train_batch_size:
  desc: null
  value: 16
train_custom_parameters_only:
  desc: null
  value: false
use_cached_eval_features:
  desc: null
  value: false
use_early_stopping:
  desc: null
  value: false
use_hf_datasets:
  desc: null
  value: false
use_multiprocessing:
  desc: null
  value: false
use_multiprocessing_for_evaluation:
  desc: null
  value: true
wandb_kwargs:
  desc: null
  value: {}
wandb_project:
  desc: null
  value: ACSA-generation
warmup_ratio:
  desc: null
  value: 0.06
warmup_steps:
  desc: null
  value: 4224
weight_decay:
  desc: null
  value: 0.0
model_class:
  desc: null
  value: Seq2SeqModel
base_marian_model_name:
  desc: null
  value: gogamza/kobart-base-v2
dataset_class:
  desc: null
  value: null
dataset_cache_dir:
  desc: null
  value: null
do_sample:
  desc: null
  value: false
early_stopping:
  desc: null
  value: true
evaluate_generated_text:
  desc: null
  value: false
faiss_d:
  desc: null
  value: 768
faiss_m:
  desc: null
  value: 128
include_title_in_knowledge_dataset:
  desc: null
  value: true
length_penalty:
  desc: null
  value: 2.0
max_length:
  desc: null
  value: 256
max_steps:
  desc: null
  value: -1
num_beams:
  desc: null
  value: 1
num_return_sequences:
  desc: null
  value: 1
rag_embed_batch_size:
  desc: null
  value: 16
repetition_penalty:
  desc: null
  value: 1.0
save_knowledge_dataset:
  desc: null
  value: true
save_knowledge_dataset_with_checkpoints:
  desc: null
  value: false
split_text_character:
  desc: null
  value: ' '
split_text_n:
  desc: null
  value: 100
src_lang:
  desc: null
  value: en_XX
tgt_lang:
  desc: null
  value: ro_RO
top_k:
  desc: null
  value: null
top_p:
  desc: null
  value: null
use_multiprocessed_decoding:
  desc: null
  value: false
_wandb:
  desc: null
  value:
    python_version: 3.9.16
    cli_version: 0.15.8
    framework: huggingface
    huggingface_version: 4.31.0
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1694018846.332479
    t:
      1:
      - 1
      - 2
      - 3
      - 5
      - 11
      - 31
      - 49
      - 51
      - 53
      - 55
      2:
      - 1
      - 2
      - 3
      - 5
      - 11
      - 31
      - 49
      - 51
      - 53
      - 55
      3:
      - 1
      - 16
      - 23
      4: 3.9.16
      5: 0.15.8
      6: 4.31.0
      8:
      - 3
      - 5
