
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "                                                            | 0/4693 [00:04<?, ?it/s]








  warnings.warn("To get the last learning rate computed by the scheduler, "                                                            | 49/4693 [00:22<26:40,  2.90it/s]

























































































































































































































































































































































































































































































Traceback (most recent call last):98:  59%|█████████████████████████████████████████████████████▎                                    | 2783/4693 [16:14<10:52,  2.93it/s]
  File "C:\Users\bestm\Desktop\Dev\AIKU\ABSA\ACSA-generation\train_MAMS_sentiment.py", line 62, in <module>
    best_accuracy = model.train_model(train_df, best_accuracy)
  File "C:\Users\bestm\Desktop\Dev\AIKU\ABSA\ACSA-generation\seq2seq_model_M.py", line 283, in train_model
    global_step, tr_loss, best_accuracy = self.train(
  File "C:\Users\bestm\Desktop\Dev\AIKU\ABSA\ACSA-generation\seq2seq_model_M.py", line 496, in train
    scaler.scale(loss).backward()
  File "C:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\_tensor.py", line 488, in backward
    torch.autograd.backward(
  File "C:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\autograd\__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt