{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jprcZhTyetFF"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 11590,
     "status": "ok",
     "timestamp": 1693322189994,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "Q28akqg88aFa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, ConcatDataset\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, BatchEncoding\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "\n",
    "from typing import Optional, Dict, Tuple, List, Callable\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhpx9K0z8gWE"
   },
   "source": [
    "# Configurations, Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "torch.manual_seed(421)\n",
    "torch.cuda.manual_seed(421)\n",
    "torch.cuda.manual_seed_all(421)\n",
    "np.random.seed(421)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(421)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1693322189994,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "HkEPwXOXNSp_"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataArgs:\n",
    "  train_dataset_path: str = '../data/nikluge-sa-2022-train.jsonl'\n",
    "  # train_dataset_path: str = '../data/nikluge-sa-2022-train_augmented.jsonl'\n",
    "  augmented_dataset_path: str = '../data/for_cd_train.jsonl'\n",
    "  val_dataset_path: str = '../data/nikluge-sa-2022-dev.jsonl'\n",
    "  test_dataset_path: str = '../data/nikluge-sa-2022-test.jsonl'\n",
    "  batch_size: int = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1693322189994,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "4m7AUUjaOcgq"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArgs:\n",
    "  max_tokens: int = 32\n",
    "  huggingface_baseline: str = 'klue/roberta-small' #\"beomi/KcELECTRA-base-v2022\"\n",
    "  dropout: float = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1693322189995,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "3NZ_4E9fOelJ"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingArgs:\n",
    "  n_epochs: int = 25\n",
    "  lr: float = 2e-5\n",
    "  save_path: str = '../saved_model/'\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1693322189995,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "8LDwADWNMpsC"
   },
   "outputs": [],
   "source": [
    "category_main_id2name = ['패키지/구성품', '제품 전체', '본품', '브랜드']\n",
    "category_main_name2id = {category_main_id2name[i]: i for i in range(len(category_main_id2name))}\n",
    "\n",
    "category_sub_id2name = ['품질', '다양성', '인지도', '편의성', '일반', '가격', '디자인']\n",
    "category_sub_name2id = {category_sub_id2name[i]: i for i in range(len(category_sub_id2name))}\n",
    "\n",
    "category_id2name = ['제품 전체#일반', '제품 전체#가격', '제품 전체#디자인', '제품 전체#품질', '제품 전체#편의성', '제품 전체#인지도', # 6\n",
    "                    '본품#일반', '본품#디자인', '본품#품질', '본품#편의성', '본품#다양성', '본품#가격', '본품#인지도', # 7\n",
    "                    '패키지/구성품#일반', '패키지/구성품#디자인', '패키지/구성품#품질', '패키지/구성품#편의성', '패키지/구성품#다양성', '패키지/구성품#가격', '패키지/구성품#인지도', # 7\n",
    "                    '브랜드#일반', '브랜드#가격', '브랜드#디자인', '브랜드#품질', '브랜드#인지도'] # 5\n",
    "\n",
    "category_name2id = {category_id2name[i]: i for i in range(len(category_id2name))}\n",
    "\n",
    "polarity_id2name = ['positive', 'negative', 'neutral']\n",
    "polarity_name2id = {polarity_id2name[i]: i for i in range(len(polarity_id2name))}\n",
    "\n",
    "special_tokens_dict = {\n",
    "  'additional_special_tokens': ['<name>', '<affiliation>', '<social-security-num>', '<tel-num>', '<card-num>', '<bank-account>', '<num>', '<online-account>'] + ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n",
    "    # 'additional_special_tokens': ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tg3XP0-q8rOu"
   },
   "source": [
    "# Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1693322189995,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "JSjLcT8mYezD"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(\n",
    "    self,\n",
    "    path: str,\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    "    max_tokens: Optional[int] = 128,\n",
    "    is_test: bool = False\n",
    "      ):\n",
    "    self.is_test = is_test\n",
    "    self.data = self._data_preprocess(self._load_data(path, self.is_test))\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_tokens = max_tokens\n",
    "\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return len(self.data)\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx: int) -> dict:\n",
    "    row = self.data.iloc[idx, :]\n",
    "    inputs = self.tokenizer(row['sentence_form'], max_length=self.max_tokens, truncation=True, padding='max_length')\n",
    "    input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
    "    \n",
    "    if self.is_test:\n",
    "      return {\n",
    "          'input_ids': torch.LongTensor(input_ids),\n",
    "          'attention_mask': torch.LongTensor(attention_mask)\n",
    "          }\n",
    "    else:\n",
    "      labels = self._convert_to_binary(list(map(lambda x: category_name2id[x], row['category'])), n_classes=len(category_id2name))\n",
    "      return {\n",
    "          'input_ids': torch.LongTensor(input_ids),\n",
    "          'attention_mask': torch.LongTensor(attention_mask),\n",
    "          'labels': labels\n",
    "          }\n",
    "\n",
    "\n",
    "  def _convert_to_binary(self, labels: List[int], n_classes: int) -> torch.Tensor:\n",
    "    binary_labels = torch.zeros(n_classes)\n",
    "    binary_labels[labels] = 1\n",
    "    return binary_labels\n",
    "\n",
    "\n",
    "  def _load_json(self, path: str, encoding: Optional[str]=\"utf-8\") -> list:\n",
    "    with open(path, encoding=encoding) as f:\n",
    "        json_list = [json.loads(line) for line in f.readlines()]\n",
    "    return json_list\n",
    "\n",
    "\n",
    "  def _load_data(self, path: str, is_test):\n",
    "    if self.is_test:\n",
    "      df = pd.DataFrame(self._load_json(path))\n",
    "    else:\n",
    "      df = pd.DataFrame(self._load_json(path)).explode('annotation')\n",
    "      df['category'] = df['annotation'].apply(lambda x: x[0])\n",
    "      df['polarity'] = df['annotation'].apply(lambda x: x[2])\n",
    "      df = df.groupby('sentence_form').agg({'category': list, 'polarity': list}).reset_index()\n",
    "    \n",
    "    return df\n",
    "  \n",
    "  \n",
    "  def _text_normalize(self, x):\n",
    "    count = {}\n",
    "    normalized_text = \"\"\n",
    "    for char in x:\n",
    "      if char not in count:\n",
    "        count = {char: 1}\n",
    "      else:\n",
    "        count[char] += 1\n",
    "      if count[char] <= 2:\n",
    "        normalized_text += char\n",
    "    return normalized_text\n",
    "  \n",
    "  \n",
    "  def _text_preprocess(self, x):\n",
    "    emojis = ''.join(emoji.EMOJI_DATA.keys())\n",
    "    pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣]+') # {emojis}\n",
    "    x = pattern.sub('', x) # 불용어 처리 kcElectra\n",
    "    x = re.sub(' +', ' ', x) # 더블 스페이스 제거\n",
    "    x = self._text_normalize(x)\n",
    "    return x\n",
    "  \n",
    "  \n",
    "  def _data_preprocess(self, df):\n",
    "    df['sentence_form'] = df['sentence_form'].apply(self._text_preprocess)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1693322189995,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "x1jAPAid82HX"
   },
   "outputs": [],
   "source": [
    "class DataIterator():\n",
    "  def __init__(\n",
    "      self,\n",
    "      data_args: DataArgs,\n",
    "      model_args: ModelArgs,\n",
    "      tokenizer: transformers.PreTrainedTokenizer\n",
    "      ):\n",
    "#     full_dataset = CustomDataset(data_args.augmented_dataset_path, tokenizer, max_tokens=model_args.max_tokens)\n",
    "    \n",
    "#     train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [0.8, 0.2])\n",
    "    train_dataset = CustomDataset(data_args.train_dataset_path, tokenizer, max_tokens=model_args.max_tokens)\n",
    "    test_dataset = CustomDataset(data_args.val_dataset_path, tokenizer, max_tokens=model_args.max_tokens)\n",
    "    \n",
    "    self.train = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=data_args.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "        )\n",
    "\n",
    "    self.val = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=data_args.batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UU-BFyaTItwU"
   },
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCexh_hcyVgj"
   },
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1693322189995,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "rTgaCKYEIpmC"
   },
   "outputs": [],
   "source": [
    "class MultiLabelClassifierLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, n_label: int, model_args: ModelArgs):\n",
    "      super(MultiLabelClassifierLayer, self).__init__()\n",
    "      self.linear = nn.Linear(hidden_dim, hidden_dim)\n",
    "      self.batch_norm = torch.nn.BatchNorm1d(hidden_dim)\n",
    "      self.fc_out = nn.Linear(hidden_dim, n_label)\n",
    "      self.relu = torch.nn.ReLU()\n",
    "      self.dropout = nn.Dropout(model_args.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.linear(x)\n",
    "      if x.dim() == 1:\n",
    "        x = x.unsqueeze(0)\n",
    "      x = self.batch_norm(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      x = self.fc_out(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1693322189996,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "c0EH0xy5QqxU"
   },
   "outputs": [],
   "source": [
    "class AttentionPoolingLayer(nn.Module):\n",
    "  def __init__(self, hidden_dim: int):\n",
    "    super(AttentionPoolingLayer, self).__init__()\n",
    "    self.linear = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.stack([x[i][:, 0, :].squeeze() for i in range(1, len(x))])\n",
    "    attention = F.softmax(self.linear(x), dim=0)\n",
    "    x = torch.sum(attention * x, dim=0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, n_label: int, model_args: ModelArgs):\n",
    "      super(ClassifierBlock, self).__init__()\n",
    "      self.attn_pooling = AttentionPoolingLayer(hidden_dim)\n",
    "      self.classifiers = nn.ModuleList([MultiLabelClassifierLayer(hidden_dim, 1, model_args) for _ in range(n_label)])\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.attn_pooling(x)\n",
    "      x = torch.cat([classifier(x) for classifier in self.classifiers], -1)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnK4QVRtIq8H"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1693322189996,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "WkyrAEhAQBQV"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_args: ModelArgs,\n",
    "        len_tokenizer: int\n",
    "        ):\n",
    "        super(CustomModel, self).__init__()\n",
    "\n",
    "        self.roberta = AutoModel.from_pretrained(model_args.huggingface_baseline)\n",
    "        self.roberta.resize_token_embeddings(len_tokenizer)\n",
    "        \n",
    "        self.classifier_1 = ClassifierBlock(self.roberta.config.hidden_size, 6, model_args)\n",
    "        self.classifier_2 = ClassifierBlock(self.roberta.config.hidden_size, 7, model_args)\n",
    "        self.classifier_3 = ClassifierBlock(self.roberta.config.hidden_size, 7, model_args)\n",
    "        self.classifier_4 = ClassifierBlock(self.roberta.config.hidden_size, 5, model_args)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        **kwargs\n",
    "        ):\n",
    "      outputs = self.roberta(\n",
    "          input_ids=input_ids,\n",
    "          attention_mask=attention_mask,\n",
    "          output_hidden_states=True,\n",
    "          token_type_ids=None\n",
    "          )\n",
    "\n",
    "      hidden_states = outputs.hidden_states\n",
    "      outputs = torch.cat((self.classifier_1(hidden_states), \n",
    "                           self.classifier_2(hidden_states), \n",
    "                           self.classifier_3(hidden_states),\n",
    "                           self.classifier_4(hidden_states)), -1)\n",
    "\n",
    "      return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ka98lsxi--Y"
   },
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "executionInfo": {
     "elapsed": 442,
     "status": "ok",
     "timestamp": 1693323655094,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "Mu7_xv2NAPwF"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "class MetricCalculator():\n",
    "  def __init__(self, threshold):\n",
    "    self.threshold = threshold\n",
    "    self.TP = 0.001\n",
    "    self.FP = 0.001\n",
    "    self.FN = 0.001\n",
    "\n",
    "\n",
    "  def print(self):\n",
    "    precision = self.TP / (self.TP + self.FP)\n",
    "    recall = self.TP / (self.TP + self.FN)\n",
    "    print(f'국립국어원 기준 | Threshold: {self.threshold} | # Precision : {precision:.4f} | Recall : {recall:.4f} | F1 : {2 * precision * recall / (precision + recall):.4f}')\n",
    "\n",
    "\n",
    "  def clean(self):\n",
    "    self.TP = 0.001\n",
    "    self.FP = 0.001\n",
    "    self.FN = 0.001\n",
    "\n",
    "\n",
    "  def calc(self, y_prob, y_true):\n",
    "    y_pred = (torch.sigmoid(y_prob).cpu() > self.threshold)\n",
    "    y_true = y_true.cpu()\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "      a = set(np.where(y_pred[i])[0].tolist())\n",
    "      b = set(np.where(y_true[i])[0].tolist())\n",
    "      self.TP += len(set.intersection(a, b))\n",
    "      self.FP += len(a - b)\n",
    "      self.FN += len(b - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1693324259491,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "YL0yp7zSaX9B"
   },
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, model: nn.Module, optimizer: torch.optim, data_iterator: DataIterator, loss_fn, training_args: TrainingArgs,\n",
    "                 scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None):\n",
    "        self.device = training_args.device\n",
    "        self.model = model.to(self.device)\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler if scheduler else None\n",
    "        self.data_iterator = data_iterator\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        \n",
    "        self.metric_calculator_065 = MetricCalculator(0.65)\n",
    "        self.metric_calculator_07 = MetricCalculator(0.7)\n",
    "        self.metric_calculator_075 = MetricCalculator(0.75)\n",
    "        self.metric_calculator_08 = MetricCalculator(0.8)\n",
    "\n",
    "        self.save_path = training_args.save_path\n",
    "\n",
    "\n",
    "    def fit(self, epochs):\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            self.train(epoch)\n",
    "            self.val(epoch)\n",
    "\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self._train_step(epoch, self.data_iterator.train)\n",
    "\n",
    "\n",
    "    def val(self, epoch):\n",
    "        self._val_step(epoch, self.data_iterator.val)\n",
    "\n",
    "\n",
    "    def _train_step(self, epoch, data_loader):\n",
    "        data_iter = tqdm.tqdm(enumerate(data_loader), desc=f\"train #{epoch}\",\n",
    "                              total=len(data_loader), bar_format=\"{l_bar}{bar:30}{r_bar}{bar:-30b}\")\n",
    "        self.model.train()\n",
    "        running_loss = []\n",
    "        for i, data in data_iter:\n",
    "            data = {k: v.to(self.device) for k, v in data.items()}\n",
    "            labels = data['labels']\n",
    "            logits = self.model.forward(**data)\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            if self.scheduler: self.scheduler.step()\n",
    "            running_loss.append(loss.item())\n",
    "            data_iter.set_postfix({\n",
    "                \"epoch\": epoch,\n",
    "                \"iteration\": i,\n",
    "                \"loss\": sum(running_loss) / len(running_loss)})\n",
    "            \n",
    "            self.metric_calculator_065.calc(logits, labels)\n",
    "            self.metric_calculator_07.calc(logits, labels)\n",
    "            self.metric_calculator_075.calc(logits, labels)\n",
    "            self.metric_calculator_08.calc(logits, labels)\n",
    "            \n",
    "        self.train_loss += running_loss\n",
    "\n",
    "        self.metric_calculator_065.print()\n",
    "        self.metric_calculator_065.clean()\n",
    "\n",
    "        self.metric_calculator_07.print()\n",
    "        self.metric_calculator_07.clean()\n",
    "        \n",
    "        self.metric_calculator_075.print()\n",
    "        self.metric_calculator_075.clean()\n",
    "\n",
    "        self.metric_calculator_08.print()\n",
    "        self.metric_calculator_08.clean()\n",
    "\n",
    "\n",
    "\n",
    "    def _val_step(self, epoch, data_loader):\n",
    "        data_iter = tqdm.tqdm(enumerate(data_loader), desc=f\"val #{epoch}\",\n",
    "                              total=len(data_loader), bar_format=\"{l_bar}{bar:30}{r_bar}{bar:-30b}\")\n",
    "        self.model.eval()\n",
    "        running_loss = []\n",
    "        for i, data in data_iter:\n",
    "            data = {k: v.to(self.device) for k, v in data.items()}\n",
    "            labels = data['labels']\n",
    "            with torch.no_grad():\n",
    "                logits = self.model.forward(**data)\n",
    "                loss = self.loss_fn(logits, labels)\n",
    "            running_loss.append(loss.item())\n",
    "            data_iter.set_postfix({\n",
    "                \"epoch\": epoch,\n",
    "                \"iteration\": i,\n",
    "                \"loss\": sum(running_loss) / len(running_loss)})\n",
    "            self.metric_calculator_065.calc(logits, labels)\n",
    "            self.metric_calculator_07.calc(logits, labels)\n",
    "            self.metric_calculator_075.calc(logits, labels)\n",
    "            self.metric_calculator_08.calc(logits, labels)\n",
    "\n",
    "        running_loss = sum(running_loss) / len(running_loss)\n",
    "        if True:# not running_loss or (running_loss < (min(self.test_loss) if self.test_loss else 0)):\n",
    "            self.save(epoch, self.save_path, f\"{running_loss:.3}\")\n",
    "            pass\n",
    "\n",
    "        self.test_loss.append(running_loss)\n",
    "\n",
    "        self.metric_calculator_065.print()\n",
    "        self.metric_calculator_065.clean()\n",
    "\n",
    "        self.metric_calculator_07.print()\n",
    "        self.metric_calculator_07.clean()\n",
    "        \n",
    "        self.metric_calculator_075.print()\n",
    "        self.metric_calculator_075.clean()\n",
    "\n",
    "        self.metric_calculator_08.print()\n",
    "        self.metric_calculator_08.clean()\n",
    "\n",
    "\n",
    "    def save(self, epoch, file_path, loss):\n",
    "        file_path = os.path.join(file_path, f\"cd_new{loss}.pt\")\n",
    "        torch.save(self.model.state_dict(), file_path)\n",
    "        self.model.to(self.device)\n",
    "        print(f\"EP:{epoch} | Model Saved on: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6820,
     "status": "ok",
     "timestamp": 1693324266734,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "CdaiiYWEbTMQ",
    "outputId": "c17be0ea-3f94-40e9-ffd3-d90898f4817a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\owj04\\anaconda3\\envs\\AIKU\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_args = ModelArgs()\n",
    "data_args = DataArgs()\n",
    "training_args = TrainingArgs()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_args.huggingface_baseline)\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "model = CustomModel(model_args, len_tokenizer = len(tokenizer))\n",
    "optimizer = AdamW(params=filter(lambda x: x.requires_grad, model.parameters()), lr=training_args.lr)\n",
    "data_iterator = DataIterator(data_args, model_args, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1693324266734,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "hS6qcEZlHzNf",
    "outputId": "c40db1b4-c06f-4474-d12b-e00cc3e7879b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "2793\n",
      "['제품 전체#가격', '제품 전체#디자인', '제품 전체#편의성', '제품 전체#인지도', '본품#디자인', '본품#편의성', '본품#다양성', '본품#가격', '본품#인지도', '패키지/구성품#일반', '패키지/구성품#디자인', '패키지/구성품#품질', '패키지/구성품#편의성', '패키지/구성품#다양성', '패키지/구성품#가격', '패키지/구성품#인지도', '브랜드#일반', '브랜드#가격', '브랜드#디자인', '브랜드#품질', '브랜드#인지도']\n"
     ]
    }
   ],
   "source": [
    "print(len(data_iterator.train.dataset))\n",
    "print(len(data_iterator.val.dataset))\n",
    "\n",
    "count = []\n",
    "for x in data_iterator.train.dataset:\n",
    "  count.append(x['labels'].tolist())\n",
    "count = torch.Tensor(list(map(lambda x: sum(x), zip(*count))))\n",
    "\n",
    "sample_per_cls = torch.Tensor(count + np.ones(len(category_id2name)))\n",
    "print([category_id2name[x] for x in np.where(np.array(sample_per_cls < 200))[0].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLossWithPosWeight(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, pos_weight=None, reduction='mean'):\n",
    "        super(FocalLossWithPosWeight, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, target, reduction='none', pos_weight=self.pos_weight)\n",
    "\n",
    "        p_t = torch.exp(-bce_loss)\n",
    "        focal_loss = (self.alpha * (1 - p_t) ** self.gamma * bce_loss)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5377, 4.0000, 4.0000, 4.0000, 4.0000, 4.0000, 4.0000, 4.0000, 1.5974,\n",
      "        4.0000, 4.0000, 4.0000, 4.0000, 4.0000, 4.0000, 4.0000, 4.0000, 4.0000,\n",
      "        4.0000, 4.0000, 4.0000, 4.0000, 4.0000, 4.0000, 4.0000],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pos_weight = (len(data_iterator.train.dataset) - sample_per_cls) / sample_per_cls\n",
    "pos_weight = torch.Tensor(pos_weight)\n",
    "pos_weight[pos_weight > 4] = 4\n",
    "print(pos_weight)\n",
    "# Distribution-Balanced Loss\n",
    "loss_fn = FocalLossWithPosWeight(alpha=1, gamma=2, pos_weight=pos_weight.to(training_args.device), reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 118508,
     "status": "error",
     "timestamp": 1693324385239,
     "user": {
      "displayName": "‍오원준[ 학부재학 / 컴퓨터학과 ]",
      "userId": "02288428115601438567"
     },
     "user_tz": -540
    },
    "id": "TZ8vLdP2H0dK",
    "outputId": "6bc49eca-f76f-4970-c0e6-83d3e9c6cf25",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #1: 100%|██████████████████████████████| 11/11 [00:30<00:00,  2.79s/it, epoch=1, iteration=10, loss=0.262]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.0606 | Recall : 0.1399 | F1 : 0.0846\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.0592 | Recall : 0.0631 | F1 : 0.0611\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.0622 | Recall : 0.0274 | F1 : 0.0380\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.0425 | Recall : 0.0067 | F1 : 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #1: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.15it/s, epoch=1, iteration=9, loss=0.22]           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:1 | Model Saved on: ../saved_model/cd_new0.22.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.5000 | Recall : 0.0000 | F1 : 0.0000\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.5000 | Recall : 0.0000 | F1 : 0.0000\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.5000 | Recall : 0.0000 | F1 : 0.0000\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.5000 | Recall : 0.0000 | F1 : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #2: 100%|██████████████████████████████| 11/11 [00:22<00:00,  2.06s/it, epoch=2, iteration=10, loss=0.235]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.1489 | Recall : 0.3129 | F1 : 0.2018\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.1947 | Recall : 0.1948 | F1 : 0.1948\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.2461 | Recall : 0.1057 | F1 : 0.1479\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.3201 | Recall : 0.0510 | F1 : 0.0880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #2: 100%|██████████████████████████████| 10/10 [00:09<00:00,  1.06it/s, epoch=2, iteration=9, loss=0.217]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:2 | Model Saved on: ../saved_model/cd_new0.217.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.5000 | Recall : 0.0000 | F1 : 0.0000\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.5000 | Recall : 0.0000 | F1 : 0.0000\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.5000 | Recall : 0.0000 | F1 : 0.0000\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.5000 | Recall : 0.0000 | F1 : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #3: 100%|██████████████████████████████| 11/11 [00:23<00:00,  2.16s/it, epoch=3, iteration=10, loss=0.211]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.2335 | Recall : 0.4875 | F1 : 0.3158\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.3301 | Recall : 0.3721 | F1 : 0.3498\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.4626 | Recall : 0.2658 | F1 : 0.3376\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.6037 | Recall : 0.1631 | F1 : 0.2568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #3: 100%|██████████████████████████████| 10/10 [00:09<00:00,  1.02it/s, epoch=3, iteration=9, loss=0.205]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:3 | Model Saved on: ../saved_model/cd_new0.205.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.9997 | Recall : 0.0011 | F1 : 0.0022\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.5000 | Recall : 0.0000 | F1 : 0.0000\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.5000 | Recall : 0.0000 | F1 : 0.0000\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.5000 | Recall : 0.0000 | F1 : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #4: 100%|██████████████████████████████| 11/11 [00:18<00:00,  1.72s/it, epoch=4, iteration=10, loss=0.191]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.2981 | Recall : 0.5631 | F1 : 0.3898\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.4179 | Recall : 0.4492 | F1 : 0.4330\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.5661 | Recall : 0.3380 | F1 : 0.4233\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.6867 | Recall : 0.2168 | F1 : 0.3295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #4: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.17it/s, epoch=4, iteration=9, loss=0.186]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:4 | Model Saved on: ../saved_model/cd_new0.186.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.7927 | Recall : 0.2223 | F1 : 0.3472\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.8750 | Recall : 0.0763 | F1 : 0.1403\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.9583 | Recall : 0.0167 | F1 : 0.0328\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9995 | Recall : 0.0007 | F1 : 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #5: 100%|██████████████████████████████| 11/11 [00:19<00:00,  1.74s/it, epoch=5, iteration=10, loss=0.174]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.3525 | Recall : 0.5931 | F1 : 0.4422\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.4871 | Recall : 0.4925 | F1 : 0.4898\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.6087 | Recall : 0.3712 | F1 : 0.4612\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7317 | Recall : 0.2499 | F1 : 0.3726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #5: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.17it/s, epoch=5, iteration=9, loss=0.162]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:5 | Model Saved on: ../saved_model/cd_new0.162.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.7314 | Recall : 0.5212 | F1 : 0.6087\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.8120 | Recall : 0.3938 | F1 : 0.5303\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.8641 | Recall : 0.2332 | F1 : 0.3673\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9011 | Recall : 0.0926 | F1 : 0.1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #6: 100%|██████████████████████████████| 11/11 [00:26<00:00,  2.43s/it, epoch=6, iteration=10, loss=0.157]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.4138 | Recall : 0.6494 | F1 : 0.5055\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.5503 | Recall : 0.5476 | F1 : 0.5490\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.6660 | Recall : 0.4227 | F1 : 0.5172\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7701 | Recall : 0.2975 | F1 : 0.4292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #6: 100%|██████████████████████████████| 10/10 [00:19<00:00,  1.95s/it, epoch=6, iteration=9, loss=0.141]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:6 | Model Saved on: ../saved_model/cd_new0.141.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6748 | Recall : 0.6339 | F1 : 0.6537\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7413 | Recall : 0.5412 | F1 : 0.6257\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.8100 | Recall : 0.4413 | F1 : 0.5714\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8698 | Recall : 0.3131 | F1 : 0.4605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #7: 100%|██████████████████████████████| 11/11 [00:37<00:00,  3.41s/it, epoch=7, iteration=10, loss=0.145]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.4533 | Recall : 0.6658 | F1 : 0.5394\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.5845 | Recall : 0.5613 | F1 : 0.5726\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7042 | Recall : 0.4491 | F1 : 0.5484\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7977 | Recall : 0.3225 | F1 : 0.4593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #7: 100%|██████████████████████████████| 10/10 [00:19<00:00,  2.00s/it, epoch=7, iteration=9, loss=0.127]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:7 | Model Saved on: ../saved_model/cd_new0.127.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6421 | Recall : 0.6517 | F1 : 0.6468\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7127 | Recall : 0.5768 | F1 : 0.6376\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7739 | Recall : 0.4798 | F1 : 0.5924\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8261 | Recall : 0.3709 | F1 : 0.5119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #8: 100%|██████████████████████████████| 11/11 [00:39<00:00,  3.61s/it, epoch=8, iteration=10, loss=0.134]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.5076 | Recall : 0.6878 | F1 : 0.5841\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.6366 | Recall : 0.5895 | F1 : 0.6121\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7361 | Recall : 0.4862 | F1 : 0.5856\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8097 | Recall : 0.3685 | F1 : 0.5065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #8: 100%|██████████████████████████████| 10/10 [00:17<00:00,  1.78s/it, epoch=8, iteration=9, loss=0.116]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:8 | Model Saved on: ../saved_model/cd_new0.116.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6515 | Recall : 0.6709 | F1 : 0.6611\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7186 | Recall : 0.6066 | F1 : 0.6579\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7781 | Recall : 0.5387 | F1 : 0.6366\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8349 | Recall : 0.4482 | F1 : 0.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #9: 100%|██████████████████████████████| 11/11 [00:28<00:00,  2.62s/it, epoch=9, iteration=10, loss=0.124]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.5460 | Recall : 0.7094 | F1 : 0.6171\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.6625 | Recall : 0.6242 | F1 : 0.6428\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7547 | Recall : 0.5306 | F1 : 0.6231\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8321 | Recall : 0.4108 | F1 : 0.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #9: 100%|██████████████████████████████| 10/10 [00:09<00:00,  1.02it/s, epoch=9, iteration=9, loss=0.108]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:9 | Model Saved on: ../saved_model/cd_new0.108.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6512 | Recall : 0.6851 | F1 : 0.6677\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7130 | Recall : 0.6299 | F1 : 0.6689\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7641 | Recall : 0.5623 | F1 : 0.6478\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8243 | Recall : 0.4773 | F1 : 0.6046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #10: 100%|██████████████████████████████| 11/11 [00:22<00:00,  2.07s/it, epoch=10, iteration=10, loss=0.113]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.5904 | Recall : 0.7339 | F1 : 0.6544\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7123 | Recall : 0.6562 | F1 : 0.6831\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7941 | Recall : 0.5465 | F1 : 0.6474\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8631 | Recall : 0.4268 | F1 : 0.5712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #10: 100%|██████████████████████████████| 10/10 [00:09<00:00,  1.09it/s, epoch=10, iteration=9, loss=0.102]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:10 | Model Saved on: ../saved_model/cd_new0.102.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6594 | Recall : 0.6898 | F1 : 0.6742\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7098 | Recall : 0.6237 | F1 : 0.6640\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7661 | Recall : 0.5579 | F1 : 0.6456\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8162 | Recall : 0.4758 | F1 : 0.6012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #11: 100%|██████████████████████████████| 11/11 [00:21<00:00,  1.99s/it, epoch=11, iteration=10, loss=0.106]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6199 | Recall : 0.7304 | F1 : 0.6706\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7228 | Recall : 0.6561 | F1 : 0.6879\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.8008 | Recall : 0.5598 | F1 : 0.6590\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8624 | Recall : 0.4365 | F1 : 0.5796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #11: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.23it/s, epoch=11, iteration=9, loss=0.0952]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:11 | Model Saved on: ../saved_model/cd_new0.0952.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6551 | Recall : 0.6942 | F1 : 0.6741\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7086 | Recall : 0.6411 | F1 : 0.6732\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7621 | Recall : 0.5772 | F1 : 0.6569\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8126 | Recall : 0.5042 | F1 : 0.6223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #12: 100%|██████████████████████████████| 11/11 [00:21<00:00,  1.97s/it, epoch=12, iteration=10, loss=0.0959]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6545 | Recall : 0.7641 | F1 : 0.7051\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7505 | Recall : 0.6908 | F1 : 0.7195\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.8264 | Recall : 0.5987 | F1 : 0.6943\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8787 | Recall : 0.4702 | F1 : 0.6126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #12: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.22it/s, epoch=12, iteration=9, loss=0.093]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:12 | Model Saved on: ../saved_model/cd_new0.093.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6515 | Recall : 0.6880 | F1 : 0.6693\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7034 | Recall : 0.6400 | F1 : 0.6702\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7593 | Recall : 0.5855 | F1 : 0.6612\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8071 | Recall : 0.5151 | F1 : 0.6288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #13: 100%|██████████████████████████████| 11/11 [00:22<00:00,  2.02s/it, epoch=13, iteration=10, loss=0.0883]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6844 | Recall : 0.7760 | F1 : 0.7274\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7682 | Recall : 0.6969 | F1 : 0.7308\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.8283 | Recall : 0.6185 | F1 : 0.7082\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8766 | Recall : 0.4930 | F1 : 0.6311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #13: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.15it/s, epoch=13, iteration=9, loss=0.0895]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:13 | Model Saved on: ../saved_model/cd_new0.0895.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6660 | Recall : 0.6851 | F1 : 0.6754\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7165 | Recall : 0.6371 | F1 : 0.6745\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7651 | Recall : 0.5834 | F1 : 0.6620\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8146 | Recall : 0.5202 | F1 : 0.6349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #14: 100%|██████████████████████████████| 11/11 [00:21<00:00,  1.95s/it, epoch=14, iteration=10, loss=0.0819]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.7228 | Recall : 0.8018 | F1 : 0.7603\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7993 | Recall : 0.7415 | F1 : 0.7693\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.8553 | Recall : 0.6656 | F1 : 0.7486\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8973 | Recall : 0.5556 | F1 : 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #14: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.22it/s, epoch=14, iteration=9, loss=0.0872]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:14 | Model Saved on: ../saved_model/cd_new0.0872.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6668 | Recall : 0.6862 | F1 : 0.6763\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7118 | Recall : 0.6458 | F1 : 0.6772\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7571 | Recall : 0.5910 | F1 : 0.6638\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8010 | Recall : 0.5380 | F1 : 0.6436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #15: 100%|██████████████████████████████| 11/11 [00:22<00:00,  2.05s/it, epoch=15, iteration=10, loss=0.0758]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.7333 | Recall : 0.8068 | F1 : 0.7683\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.8059 | Recall : 0.7512 | F1 : 0.7776\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.8621 | Recall : 0.6849 | F1 : 0.7633\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9046 | Recall : 0.5720 | F1 : 0.7008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #15: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.19it/s, epoch=15, iteration=9, loss=0.0835]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:15 | Model Saved on: ../saved_model/cd_new0.0835.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6792 | Recall : 0.6883 | F1 : 0.6837\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7141 | Recall : 0.6469 | F1 : 0.6789\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7538 | Recall : 0.5972 | F1 : 0.6664\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.8027 | Recall : 0.5423 | F1 : 0.6473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #16: 100%|██████████████████████████████| 11/11 [00:21<00:00,  1.97s/it, epoch=16, iteration=10, loss=0.0688]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.7646 | Recall : 0.8317 | F1 : 0.7967\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.8316 | Recall : 0.7837 | F1 : 0.8069\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.8834 | Recall : 0.7043 | F1 : 0.7838\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9241 | Recall : 0.6003 | F1 : 0.7278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #16: 100%|██████████████████████████████| 10/10 [00:07<00:00,  1.38it/s, epoch=16, iteration=9, loss=0.0829]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:16 | Model Saved on: ../saved_model/cd_new0.0829.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6709 | Recall : 0.6858 | F1 : 0.6783\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7074 | Recall : 0.6498 | F1 : 0.6774\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7500 | Recall : 0.6081 | F1 : 0.6716\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7938 | Recall : 0.5550 | F1 : 0.6533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #17: 100%|██████████████████████████████| 11/11 [00:22<00:00,  2.09s/it, epoch=17, iteration=10, loss=0.0646]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.7771 | Recall : 0.8360 | F1 : 0.8055\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.8391 | Recall : 0.7889 | F1 : 0.8132\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.8915 | Recall : 0.7214 | F1 : 0.7975\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9213 | Recall : 0.6253 | F1 : 0.7449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #17: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.21it/s, epoch=17, iteration=9, loss=0.0813]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:17 | Model Saved on: ../saved_model/cd_new0.0813.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6811 | Recall : 0.6891 | F1 : 0.6851\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7079 | Recall : 0.6487 | F1 : 0.6770\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7489 | Recall : 0.6055 | F1 : 0.6696\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7934 | Recall : 0.5608 | F1 : 0.6572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #18: 100%|██████████████████████████████| 11/11 [00:24<00:00,  2.20s/it, epoch=18, iteration=10, loss=0.0577]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.8146 | Recall : 0.8501 | F1 : 0.8320\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.8686 | Recall : 0.7999 | F1 : 0.8329\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.9122 | Recall : 0.7461 | F1 : 0.8208\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9436 | Recall : 0.6617 | F1 : 0.7779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #18: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.21it/s, epoch=18, iteration=9, loss=0.0813]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:18 | Model Saved on: ../saved_model/cd_new0.0813.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6706 | Recall : 0.6818 | F1 : 0.6762\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7071 | Recall : 0.6444 | F1 : 0.6743\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7411 | Recall : 0.5895 | F1 : 0.6567\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7856 | Recall : 0.5416 | F1 : 0.6412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #19: 100%|██████████████████████████████| 11/11 [00:23<00:00,  2.17s/it, epoch=19, iteration=10, loss=0.0534]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.8191 | Recall : 0.8711 | F1 : 0.8443\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.8746 | Recall : 0.8337 | F1 : 0.8536\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.9110 | Recall : 0.7729 | F1 : 0.8363\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9428 | Recall : 0.6884 | F1 : 0.7958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #19: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.22it/s, epoch=19, iteration=9, loss=0.0809]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:19 | Model Saved on: ../saved_model/cd_new0.0809.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6782 | Recall : 0.6774 | F1 : 0.6778\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7155 | Recall : 0.6506 | F1 : 0.6815\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7453 | Recall : 0.6092 | F1 : 0.6704\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7804 | Recall : 0.5616 | F1 : 0.6531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #20: 100%|██████████████████████████████| 11/11 [00:20<00:00,  1.88s/it, epoch=20, iteration=10, loss=0.049]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.8424 | Recall : 0.8811 | F1 : 0.8613\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.8914 | Recall : 0.8398 | F1 : 0.8648\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.9233 | Recall : 0.7825 | F1 : 0.8471\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9508 | Recall : 0.7079 | F1 : 0.8115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #20: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.15it/s, epoch=20, iteration=9, loss=0.0817]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:20 | Model Saved on: ../saved_model/cd_new0.0817.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6892 | Recall : 0.6636 | F1 : 0.6762\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7196 | Recall : 0.6291 | F1 : 0.6713\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7523 | Recall : 0.6001 | F1 : 0.6676\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7929 | Recall : 0.5590 | F1 : 0.6557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #21: 100%|██████████████████████████████| 11/11 [00:20<00:00,  1.83s/it, epoch=21, iteration=10, loss=0.0454]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.8563 | Recall : 0.8906 | F1 : 0.8731\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.8974 | Recall : 0.8549 | F1 : 0.8756\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.9282 | Recall : 0.8065 | F1 : 0.8631\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9544 | Recall : 0.7338 | F1 : 0.8297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #21: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.23it/s, epoch=21, iteration=9, loss=0.083]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:21 | Model Saved on: ../saved_model/cd_new0.083.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6618 | Recall : 0.6702 | F1 : 0.6659\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.6988 | Recall : 0.6448 | F1 : 0.6707\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7299 | Recall : 0.6095 | F1 : 0.6643\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7682 | Recall : 0.5659 | F1 : 0.6517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #22: 100%|██████████████████████████████| 11/11 [00:21<00:00,  1.97s/it, epoch=22, iteration=10, loss=0.041]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.8761 | Recall : 0.9035 | F1 : 0.8896\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.9201 | Recall : 0.8693 | F1 : 0.8939\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.9450 | Recall : 0.8230 | F1 : 0.8798\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9683 | Recall : 0.7618 | F1 : 0.8527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #22: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.22it/s, epoch=22, iteration=9, loss=0.0848]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:22 | Model Saved on: ../saved_model/cd_new0.0848.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6773 | Recall : 0.6724 | F1 : 0.6748\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7083 | Recall : 0.6484 | F1 : 0.6770\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7415 | Recall : 0.6211 | F1 : 0.6760\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7730 | Recall : 0.5899 | F1 : 0.6691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #23: 100%|██████████████████████████████| 11/11 [00:20<00:00,  1.88s/it, epoch=23, iteration=10, loss=0.0378]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.8843 | Recall : 0.9173 | F1 : 0.9005\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.9153 | Recall : 0.8893 | F1 : 0.9021\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.9436 | Recall : 0.8477 | F1 : 0.8931\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9636 | Recall : 0.7860 | F1 : 0.8658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #23: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.16it/s, epoch=23, iteration=9, loss=0.0817]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:23 | Model Saved on: ../saved_model/cd_new0.0817.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6806 | Recall : 0.6673 | F1 : 0.6739\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7089 | Recall : 0.6404 | F1 : 0.6729\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7366 | Recall : 0.6106 | F1 : 0.6677\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7691 | Recall : 0.5710 | F1 : 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #24: 100%|██████████████████████████████| 11/11 [00:20<00:00,  1.88s/it, epoch=24, iteration=10, loss=0.0342]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.8912 | Recall : 0.9141 | F1 : 0.9025\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.9256 | Recall : 0.8911 | F1 : 0.9080\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.9494 | Recall : 0.8508 | F1 : 0.8974\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9691 | Recall : 0.7948 | F1 : 0.8734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #24: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.16it/s, epoch=24, iteration=9, loss=0.0839]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:24 | Model Saved on: ../saved_model/cd_new0.0839.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6871 | Recall : 0.6731 | F1 : 0.6800\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7184 | Recall : 0.6506 | F1 : 0.6828\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7476 | Recall : 0.6219 | F1 : 0.6790\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7742 | Recall : 0.5917 | F1 : 0.6708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train #25: 100%|██████████████████████████████| 11/11 [00:20<00:00,  1.88s/it, epoch=25, iteration=10, loss=0.031]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.9076 | Recall : 0.9310 | F1 : 0.9192\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.9394 | Recall : 0.9093 | F1 : 0.9241\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.9604 | Recall : 0.8739 | F1 : 0.9151\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.9757 | Recall : 0.8169 | F1 : 0.8893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val #25: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.23it/s, epoch=25, iteration=9, loss=0.0859]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP:25 | Model Saved on: ../saved_model/cd_new0.0859.pt\n",
      "국립국어원 기준 | Threshold: 0.65 | # Precision : 0.6859 | Recall : 0.6742 | F1 : 0.6800\n",
      "국립국어원 기준 | Threshold: 0.7 | # Precision : 0.7111 | Recall : 0.6509 | F1 : 0.6797\n",
      "국립국어원 기준 | Threshold: 0.75 | # Precision : 0.7385 | Recall : 0.6259 | F1 : 0.6775\n",
      "국립국어원 기준 | Threshold: 0.8 | # Precision : 0.7659 | Recall : 0.5906 | F1 : 0.6669\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, optimizer, data_iterator, loss_fn, training_args)\n",
    "trainer.fit(training_args.n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTLJM3T2jEse"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "CXlyvXxSTEQM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\owj04\\anaconda3\\envs\\AIKU\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_args = ModelArgs()\n",
    "data_args = DataArgs()\n",
    "training_args = TrainingArgs()\n",
    "model_name = 'cd_new0.0809'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_args.huggingface_baseline)\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "model = CustomModel(model_args, len_tokenizer = len(tokenizer)).to(training_args.device)\n",
    "model.load_state_dict(torch.load(os.path.join(TrainingArgs.save_path, f'{model_name}.pt')))\n",
    "model.eval()\n",
    "\n",
    "optimizer = AdamW(params=filter(lambda x: x.requires_grad, model.parameters()), lr=training_args.lr)\n",
    "test_dataset = CustomDataset(data_args.test_dataset_path, tokenizer, max_tokens=model_args.max_tokens, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2127/2127 [00:22<00:00, 95.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# labels = [data['labels'] for data in tmp]\n",
    "# labels = torch.stack(labels)\n",
    "\n",
    "pred = []\n",
    "\n",
    "for data in tqdm.tqdm(test_dataset):\n",
    "  input_ids = data['input_ids'].unsqueeze(0).to(training_args.device)\n",
    "  attention_mask = data['attention_mask'].unsqueeze(0).to(training_args.device)\n",
    "  with torch.no_grad():\n",
    "    logits = model.forward(input_ids=input_ids, attention_mask=attention_mask).cpu()\n",
    "  pred += logits\n",
    "\n",
    "pred = torch.stack(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "pred_names = []\n",
    "for p in pred:\n",
    "  idxs = np.where(torch.sigmoid(p).cpu() > threshold)[0].tolist()\n",
    "  if not idxs:\n",
    "    idxs = np.where(torch.sigmoid(p).cpu() > threshold - 0.1)[0].tolist()\n",
    "    if not idxs:\n",
    "      idxs = [torch.argmax(p)]\n",
    "  pred_name = [[category_id2name[idx], None] for idx in idxs]\n",
    "  \n",
    "  pred_names.append(pred_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.data['annotation'] = pd.Series(pred_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             [[제품 전체#일반, None]]\n",
       "1                            [[제품 전체#디자인, None]]\n",
       "2                                [[본품#일반, None]]\n",
       "3                                [[본품#일반, None]]\n",
       "4                                [[본품#일반, None]]\n",
       "                          ...                   \n",
       "2122                            [[본품#편의성, None]]\n",
       "2123                            [[본품#편의성, None]]\n",
       "2124                             [[본품#품질, None]]\n",
       "2125                        [[패키지/구성품#일반, None]]\n",
       "2126    [[제품 전체#편의성, None], [패키지/구성품#편의성, None]]\n",
       "Name: annotation, Length: 2127, dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.data['annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[본품#품질, None]]                                               579\n",
      "[[제품 전체#일반, None]]                                            382\n",
      "[[제품 전체#품질, None]]                                            244\n",
      "[[본품#일반, None]]                                               174\n",
      "[[제품 전체#디자인, None]]                                           138\n",
      "                                                             ... \n",
      "[[제품 전체#일반, None], [본품#편의성, None]]                              1\n",
      "[[제품 전체#디자인, None], [제품 전체#품질, None], [제품 전체#편의성, None]]        1\n",
      "[[제품 전체#일반, None], [제품 전체#디자인, None], [패키지/구성품#디자인, None]]      1\n",
      "[[제품 전체#편의성, None], [본품#편의성, None], [패키지/구성품#편의성, None]]        1\n",
      "[[제품 전체#품질, None], [패키지/구성품#디자인, None]]                         1\n",
      "Name: annotation, Length: 66, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.data.loc[:, 'annotation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.data.to_json(os.path.join('../results/',f'{model_name}.json'), orient='records', force_ascii=False, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
